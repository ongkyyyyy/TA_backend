[
    {
        "label": "re",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "re",
        "description": "re",
        "detail": "re",
        "documentation": {}
    },
    {
        "label": "request",
        "importPath": "flask",
        "description": "flask",
        "isExtraImport": true,
        "detail": "flask",
        "documentation": {}
    },
    {
        "label": "jsonify",
        "importPath": "flask",
        "description": "flask",
        "isExtraImport": true,
        "detail": "flask",
        "documentation": {}
    },
    {
        "label": "jsonify",
        "importPath": "flask",
        "description": "flask",
        "isExtraImport": true,
        "detail": "flask",
        "documentation": {}
    },
    {
        "label": "request",
        "importPath": "flask",
        "description": "flask",
        "isExtraImport": true,
        "detail": "flask",
        "documentation": {}
    },
    {
        "label": "request",
        "importPath": "flask",
        "description": "flask",
        "isExtraImport": true,
        "detail": "flask",
        "documentation": {}
    },
    {
        "label": "jsonify",
        "importPath": "flask",
        "description": "flask",
        "isExtraImport": true,
        "detail": "flask",
        "documentation": {}
    },
    {
        "label": "Blueprint",
        "importPath": "flask",
        "description": "flask",
        "isExtraImport": true,
        "detail": "flask",
        "documentation": {}
    },
    {
        "label": "Blueprint",
        "importPath": "flask",
        "description": "flask",
        "isExtraImport": true,
        "detail": "flask",
        "documentation": {}
    },
    {
        "label": "Blueprint",
        "importPath": "flask",
        "description": "flask",
        "isExtraImport": true,
        "detail": "flask",
        "documentation": {}
    },
    {
        "label": "request",
        "importPath": "flask",
        "description": "flask",
        "isExtraImport": true,
        "detail": "flask",
        "documentation": {}
    },
    {
        "label": "jsonify",
        "importPath": "flask",
        "description": "flask",
        "isExtraImport": true,
        "detail": "flask",
        "documentation": {}
    },
    {
        "label": "Blueprint",
        "importPath": "flask",
        "description": "flask",
        "isExtraImport": true,
        "detail": "flask",
        "documentation": {}
    },
    {
        "label": "request",
        "importPath": "flask",
        "description": "flask",
        "isExtraImport": true,
        "detail": "flask",
        "documentation": {}
    },
    {
        "label": "jsonify",
        "importPath": "flask",
        "description": "flask",
        "isExtraImport": true,
        "detail": "flask",
        "documentation": {}
    },
    {
        "label": "Flask",
        "importPath": "flask",
        "description": "flask",
        "isExtraImport": true,
        "detail": "flask",
        "documentation": {}
    },
    {
        "label": "ObjectId",
        "importPath": "bson",
        "description": "bson",
        "isExtraImport": true,
        "detail": "bson",
        "documentation": {}
    },
    {
        "label": "regex",
        "importPath": "bson",
        "description": "bson",
        "isExtraImport": true,
        "detail": "bson",
        "documentation": {}
    },
    {
        "label": "ObjectId",
        "importPath": "bson",
        "description": "bson",
        "isExtraImport": true,
        "detail": "bson",
        "documentation": {}
    },
    {
        "label": "ObjectId",
        "importPath": "bson",
        "description": "bson",
        "isExtraImport": true,
        "detail": "bson",
        "documentation": {}
    },
    {
        "label": "ObjectId",
        "importPath": "bson",
        "description": "bson",
        "isExtraImport": true,
        "detail": "bson",
        "documentation": {}
    },
    {
        "label": "ObjectId",
        "importPath": "bson",
        "description": "bson",
        "isExtraImport": true,
        "detail": "bson",
        "documentation": {}
    },
    {
        "label": "reviews_collection",
        "importPath": "models.review",
        "description": "models.review",
        "isExtraImport": true,
        "detail": "models.review",
        "documentation": {}
    },
    {
        "label": "save_sentiment_analysis",
        "importPath": "controllers.sentiments_controller",
        "description": "controllers.sentiments_controller",
        "isExtraImport": true,
        "detail": "controllers.sentiments_controller",
        "documentation": {}
    },
    {
        "label": "get_all_sentiments",
        "importPath": "controllers.sentiments_controller",
        "description": "controllers.sentiments_controller",
        "isExtraImport": true,
        "detail": "controllers.sentiments_controller",
        "documentation": {}
    },
    {
        "label": "analyze_sentiment",
        "importPath": "sentiment_analysis.sentiment_analysis",
        "description": "sentiment_analysis.sentiment_analysis",
        "isExtraImport": true,
        "detail": "sentiment_analysis.sentiment_analysis",
        "documentation": {}
    },
    {
        "label": "analyze_sentiment",
        "importPath": "sentiment_analysis.sentiment_analysis",
        "description": "sentiment_analysis.sentiment_analysis",
        "isExtraImport": true,
        "detail": "sentiment_analysis.sentiment_analysis",
        "documentation": {}
    },
    {
        "label": "sentiment_collection",
        "importPath": "models.sentiment",
        "description": "models.sentiment",
        "isExtraImport": true,
        "detail": "models.sentiment",
        "documentation": {}
    },
    {
        "label": "sentiment_collection",
        "importPath": "models.sentiment",
        "description": "models.sentiment",
        "isExtraImport": true,
        "detail": "models.sentiment",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "detect",
        "importPath": "langdetect",
        "description": "langdetect",
        "isExtraImport": true,
        "detail": "langdetect",
        "documentation": {}
    },
    {
        "label": "LangDetectException",
        "importPath": "langdetect",
        "description": "langdetect",
        "isExtraImport": true,
        "detail": "langdetect",
        "documentation": {}
    },
    {
        "label": "MongoClient",
        "importPath": "pymongo",
        "description": "pymongo",
        "isExtraImport": true,
        "detail": "pymongo",
        "documentation": {}
    },
    {
        "label": "MongoClient",
        "importPath": "pymongo",
        "description": "pymongo",
        "isExtraImport": true,
        "detail": "pymongo",
        "documentation": {}
    },
    {
        "label": "MongoClient",
        "importPath": "pymongo",
        "description": "pymongo",
        "isExtraImport": true,
        "detail": "pymongo",
        "documentation": {}
    },
    {
        "label": "MONGO_URI",
        "importPath": "config",
        "description": "config",
        "isExtraImport": true,
        "detail": "config",
        "documentation": {}
    },
    {
        "label": "MONGO_URI",
        "importPath": "config",
        "description": "config",
        "isExtraImport": true,
        "detail": "config",
        "documentation": {}
    },
    {
        "label": "MONGO_URI",
        "importPath": "config",
        "description": "config",
        "isExtraImport": true,
        "detail": "config",
        "documentation": {}
    },
    {
        "label": "MONGO_URI",
        "importPath": "config",
        "description": "config",
        "isExtraImport": true,
        "detail": "config",
        "documentation": {}
    },
    {
        "label": "PyMongo",
        "importPath": "flask_pymongo",
        "description": "flask_pymongo",
        "isExtraImport": true,
        "detail": "flask_pymongo",
        "documentation": {}
    },
    {
        "label": "HotelController",
        "importPath": "controllers.hotel_controller",
        "description": "controllers.hotel_controller",
        "isExtraImport": true,
        "detail": "controllers.hotel_controller",
        "documentation": {}
    },
    {
        "label": "HotelsDB",
        "importPath": "models.hotels",
        "description": "models.hotels",
        "isExtraImport": true,
        "detail": "models.hotels",
        "documentation": {}
    },
    {
        "label": "hotels_collection",
        "importPath": "models.hotels",
        "description": "models.hotels",
        "isExtraImport": true,
        "detail": "models.hotels",
        "documentation": {}
    },
    {
        "label": "RevenueController",
        "importPath": "controllers.revenue_controller",
        "description": "controllers.revenue_controller",
        "isExtraImport": true,
        "detail": "controllers.revenue_controller",
        "documentation": {}
    },
    {
        "label": "RevenueDB",
        "importPath": "models.revenue",
        "description": "models.revenue",
        "isExtraImport": true,
        "detail": "models.revenue",
        "documentation": {}
    },
    {
        "label": "subprocess",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "subprocess",
        "description": "subprocess",
        "detail": "subprocess",
        "documentation": {}
    },
    {
        "label": "os",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "os",
        "description": "os",
        "detail": "os",
        "documentation": {}
    },
    {
        "label": "save_reviews",
        "importPath": "controllers.review_controller",
        "description": "controllers.review_controller",
        "isExtraImport": true,
        "detail": "controllers.review_controller",
        "documentation": {}
    },
    {
        "label": "get_all_reviews",
        "importPath": "controllers.review_controller",
        "description": "controllers.review_controller",
        "isExtraImport": true,
        "detail": "controllers.review_controller",
        "documentation": {}
    },
    {
        "label": "Counter",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "joblib",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "joblib",
        "description": "joblib",
        "detail": "joblib",
        "documentation": {}
    },
    {
        "label": "pandas",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "pandas",
        "description": "pandas",
        "detail": "pandas",
        "documentation": {}
    },
    {
        "label": "NEGATION_WORDS",
        "importPath": "sentiment_analysis.indonesian_sentiment_lexicon",
        "description": "sentiment_analysis.indonesian_sentiment_lexicon",
        "isExtraImport": true,
        "detail": "sentiment_analysis.indonesian_sentiment_lexicon",
        "documentation": {}
    },
    {
        "label": "CONTRAST_WORDS",
        "importPath": "sentiment_analysis.indonesian_sentiment_lexicon",
        "description": "sentiment_analysis.indonesian_sentiment_lexicon",
        "isExtraImport": true,
        "detail": "sentiment_analysis.indonesian_sentiment_lexicon",
        "documentation": {}
    },
    {
        "label": "LogisticRegression",
        "importPath": "sklearn.linear_model",
        "description": "sklearn.linear_model",
        "isExtraImport": true,
        "detail": "sklearn.linear_model",
        "documentation": {}
    },
    {
        "label": "TfidfVectorizer",
        "importPath": "sklearn.feature_extraction.text",
        "description": "sklearn.feature_extraction.text",
        "isExtraImport": true,
        "detail": "sklearn.feature_extraction.text",
        "documentation": {}
    },
    {
        "label": "train_test_split",
        "importPath": "sklearn.model_selection",
        "description": "sklearn.model_selection",
        "isExtraImport": true,
        "detail": "sklearn.model_selection",
        "documentation": {}
    },
    {
        "label": "classification_report",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "hstack",
        "importPath": "scipy.sparse",
        "description": "scipy.sparse",
        "isExtraImport": true,
        "detail": "scipy.sparse",
        "documentation": {}
    },
    {
        "label": "SMOTE",
        "importPath": "imblearn.over_sampling",
        "description": "imblearn.over_sampling",
        "isExtraImport": true,
        "detail": "imblearn.over_sampling",
        "documentation": {}
    },
    {
        "label": "array",
        "importPath": "numpy",
        "description": "numpy",
        "isExtraImport": true,
        "detail": "numpy",
        "documentation": {}
    },
    {
        "label": "create_revenue_blueprint",
        "importPath": "routes.revenue_routes",
        "description": "routes.revenue_routes",
        "isExtraImport": true,
        "detail": "routes.revenue_routes",
        "documentation": {}
    },
    {
        "label": "create_review_blueprint",
        "importPath": "routes.review_routes",
        "description": "routes.review_routes",
        "isExtraImport": true,
        "detail": "routes.review_routes",
        "documentation": {}
    },
    {
        "label": "create_sentiment_blueprint",
        "importPath": "routes.sentiment_routes",
        "description": "routes.sentiment_routes",
        "isExtraImport": true,
        "detail": "routes.sentiment_routes",
        "documentation": {}
    },
    {
        "label": "create_hotel_blueprint",
        "importPath": "routes.hotel_routes",
        "description": "routes.hotel_routes",
        "isExtraImport": true,
        "detail": "routes.hotel_routes",
        "documentation": {}
    },
    {
        "label": "CORS",
        "importPath": "flask_cors",
        "description": "flask_cors",
        "isExtraImport": true,
        "detail": "flask_cors",
        "documentation": {}
    },
    {
        "label": "HotelController",
        "kind": 6,
        "importPath": "controllers.hotel_controller",
        "description": "controllers.hotel_controller",
        "peekOfCode": "class HotelController:\n    def __init__(self, db):\n        self.db = db\n    def create_hotel(self):\n        data = request.json\n        required_fields = [\"hotel_name\", \"address\", \"city\", \"country\"]\n        if not all(field in data and data[field] for field in required_fields):\n            return jsonify({\"error\": \"Missing required field(s)\"}), 400\n        data.setdefault(\"agoda_link\", \"\")\n        data.setdefault(\"traveloka_link\", \"\")",
        "detail": "controllers.hotel_controller",
        "documentation": {}
    },
    {
        "label": "RevenueController",
        "kind": 6,
        "importPath": "controllers.revenue_controller",
        "description": "controllers.revenue_controller",
        "peekOfCode": "class RevenueController:\n    def __init__(self, db):\n        self.db = db\n    def get_revenues(self):\n        try:\n            revenues = self.db.get_all_revenues()\n            return jsonify({\"success\": True, \"data\": revenues}), 200\n        except Exception as e:\n            return jsonify({\"success\": False, \"error\": str(e)}), 500\n    def get_revenue(self, revenue_id):",
        "detail": "controllers.revenue_controller",
        "documentation": {}
    },
    {
        "label": "save_reviews",
        "kind": 2,
        "importPath": "controllers.review_controller",
        "description": "controllers.review_controller",
        "peekOfCode": "def save_reviews(reviews, hotel_id=None):  \n    if not reviews:\n        return {\"message\": \"No reviews to save\", \"status\": 400}\n    filters = [{\n        \"username\": r[\"username\"],\n        \"comment\": r[\"comment\"],\n        \"timestamp\": r[\"timestamp\"],\n        \"hotel_name\": r.get(\"hotel_name\", \"\"),\n        \"OTA\": r[\"OTA\"]\n    } for r in reviews]",
        "detail": "controllers.review_controller",
        "documentation": {}
    },
    {
        "label": "get_all_reviews",
        "kind": 2,
        "importPath": "controllers.review_controller",
        "description": "controllers.review_controller",
        "peekOfCode": "def get_all_reviews():\n    page = int(request.args.get('page', 1)) \n    per_page = 15\n    skip = (page - 1) * per_page\n    pipeline = [\n        {\n            \"$lookup\": {\n                \"from\": \"sentiments\", \n                \"localField\": \"_id\",\n                \"foreignField\": \"review_id\",",
        "detail": "controllers.review_controller",
        "documentation": {}
    },
    {
        "label": "save_sentiment_analysis",
        "kind": 2,
        "importPath": "controllers.sentiments_controller",
        "description": "controllers.sentiments_controller",
        "peekOfCode": "def save_sentiment_analysis(sentiments):\n    if not sentiments:\n        return {\"message\": \"No sentiment data to save\", \"status\": 400}\n    sentiment_collection.insert_many(sentiments)\n    return {\"message\": \"Sentiment analysis saved successfully\", \"status\": 201}\ndef get_all_sentiments():\n    sentiments = list(sentiment_collection.find({}, {\"_id\": 0}))  \n    return sentiments",
        "detail": "controllers.sentiments_controller",
        "documentation": {}
    },
    {
        "label": "get_all_sentiments",
        "kind": 2,
        "importPath": "controllers.sentiments_controller",
        "description": "controllers.sentiments_controller",
        "peekOfCode": "def get_all_sentiments():\n    sentiments = list(sentiment_collection.find({}, {\"_id\": 0}))  \n    return sentiments",
        "detail": "controllers.sentiments_controller",
        "documentation": {}
    },
    {
        "label": "HotelsDB",
        "kind": 6,
        "importPath": "models.hotels",
        "description": "models.hotels",
        "peekOfCode": "class HotelsDB:\n    def __init__(self, app=None):\n        self.client = MongoClient(MONGO_URI)\n        self.db = self.client.hotelPerformance\n        self.collection = self.db.hotels\n        self.revenues = self.db.revenues\nhotels_collection = HotelsDB().collection",
        "detail": "models.hotels",
        "documentation": {}
    },
    {
        "label": "hotels_collection",
        "kind": 5,
        "importPath": "models.hotels",
        "description": "models.hotels",
        "peekOfCode": "hotels_collection = HotelsDB().collection",
        "detail": "models.hotels",
        "documentation": {}
    },
    {
        "label": "RevenueDB",
        "kind": 6,
        "importPath": "models.revenue",
        "description": "models.revenue",
        "peekOfCode": "class RevenueDB:\n    def __init__(self, app):\n        self.mongo = PyMongo(app)\n    def get_all_revenues(self):\n        return list(self.mongo.db.revenues.find({}))\n    def get_revenue_by_id(self, object_id):\n        return self.mongo.db.revenues.find_one({\"_id\": object_id})\n    def calculate_revenue(self, data):\n        room_lodging = data.get(\"room_lodging\", 0)\n        rebate_discount = data.get(\"rebate_discount\", 0)",
        "detail": "models.revenue",
        "documentation": {}
    },
    {
        "label": "client",
        "kind": 5,
        "importPath": "models.review",
        "description": "models.review",
        "peekOfCode": "client = MongoClient(MONGO_URI)\ndb = client.hotelPerformance  \nreviews_collection = db.reviews",
        "detail": "models.review",
        "documentation": {}
    },
    {
        "label": "db",
        "kind": 5,
        "importPath": "models.review",
        "description": "models.review",
        "peekOfCode": "db = client.hotelPerformance  \nreviews_collection = db.reviews",
        "detail": "models.review",
        "documentation": {}
    },
    {
        "label": "reviews_collection",
        "kind": 5,
        "importPath": "models.review",
        "description": "models.review",
        "peekOfCode": "reviews_collection = db.reviews",
        "detail": "models.review",
        "documentation": {}
    },
    {
        "label": "client",
        "kind": 5,
        "importPath": "models.sentiment",
        "description": "models.sentiment",
        "peekOfCode": "client = MongoClient(MONGO_URI)\ndb = client.hotelPerformance  \nsentiment_collection = db.sentiments",
        "detail": "models.sentiment",
        "documentation": {}
    },
    {
        "label": "db",
        "kind": 5,
        "importPath": "models.sentiment",
        "description": "models.sentiment",
        "peekOfCode": "db = client.hotelPerformance  \nsentiment_collection = db.sentiments",
        "detail": "models.sentiment",
        "documentation": {}
    },
    {
        "label": "sentiment_collection",
        "kind": 5,
        "importPath": "models.sentiment",
        "description": "models.sentiment",
        "peekOfCode": "sentiment_collection = db.sentiments",
        "detail": "models.sentiment",
        "documentation": {}
    },
    {
        "label": "create_hotel_blueprint",
        "kind": 2,
        "importPath": "routes.hotel_routes",
        "description": "routes.hotel_routes",
        "peekOfCode": "def create_hotel_blueprint(app):\n    hotel_bp = Blueprint(\"hotels\", __name__)\n    db = HotelsDB(app)\n    controller = HotelController(db)\n    hotel_bp.add_url_rule(\"/hotels\", \"get_hotels\", controller.get_hotels, methods=[\"GET\"])\n    hotel_bp.add_url_rule(\"/hotels/<hotel_id>\", \"get_hotel\", controller.get_hotel, methods=[\"GET\"])\n    hotel_bp.add_url_rule(\"/hotels\", \"create_hotel\", controller.create_hotel, methods=[\"POST\"])\n    hotel_bp.add_url_rule(\"/hotels/<hotel_id>\", \"update_hotel\", controller.update_hotel, methods=[\"PUT\"])\n    hotel_bp.add_url_rule(\"/hotels/<hotel_id>\", \"delete_hotel\", controller.delete_hotel, methods=[\"DELETE\"])\n    hotel_bp.add_url_rule(\"/hotels/search\", \"search_hotels\", controller.search_hotels, methods=[\"GET\"])",
        "detail": "routes.hotel_routes",
        "documentation": {}
    },
    {
        "label": "create_revenue_blueprint",
        "kind": 2,
        "importPath": "routes.revenue_routes",
        "description": "routes.revenue_routes",
        "peekOfCode": "def create_revenue_blueprint(app):\n    revenue_bp = Blueprint(\"revenue\", __name__)\n    db = RevenueDB(app)\n    controller = RevenueController(db)\n    revenue_bp.add_url_rule(\"/revenues\", \"get_revenues\", controller.get_revenues, methods=[\"GET\"])\n    revenue_bp.add_url_rule(\"/revenues/<revenue_id>\", \"get_revenue\", controller.get_revenue, methods=[\"GET\"])\n    revenue_bp.add_url_rule(\"/revenues/by-hotel/<hotel_id>\", \"get_revenues_by_hotel\", controller.get_revenues_by_hotel, methods=[\"GET\"])\n    revenue_bp.add_url_rule(\"/revenues\", \"create_revenue\", controller.create_revenue, methods=[\"POST\"])\n    revenue_bp.add_url_rule(\"/revenues/<revenue_id>\", \"edit_revenue\", controller.edit_revenue, methods=[\"PUT\"])\n    revenue_bp.add_url_rule(\"/revenues/<revenue_id>\", \"remove_revenue\", controller.remove_revenue, methods=[\"DELETE\"])",
        "detail": "routes.revenue_routes",
        "documentation": {}
    },
    {
        "label": "create_review_blueprint",
        "kind": 2,
        "importPath": "routes.review_routes",
        "description": "routes.review_routes",
        "peekOfCode": "def create_review_blueprint(app):\n    review_bp = Blueprint(\"reviews\", __name__)\n    @review_bp.route(\"/scrape/<source>\", methods=[\"POST\"])\n    def scrape_reviews(source):\n        data = request.json\n        hotel_id = data.get(\"hotel_id\")\n        if not hotel_id:\n            return jsonify({\"error\": \"hotel_id is required\"}), 400\n        try:\n            hotel_id_obj = ObjectId(hotel_id)",
        "detail": "routes.review_routes",
        "documentation": {}
    },
    {
        "label": "create_sentiment_blueprint",
        "kind": 2,
        "importPath": "routes.sentiment_routes",
        "description": "routes.sentiment_routes",
        "peekOfCode": "def create_sentiment_blueprint(app):\n    sentiments_bp = Blueprint(\"sentiments\", __name__)\n    @sentiments_bp.route(\"/sentiments\", methods=[\"GET\"])\n    def get_sentiments():\n        sentiments = get_all_sentiments()\n        jsonify({\"reviews\": sentiments})\n    return sentiments_bp",
        "detail": "routes.sentiment_routes",
        "documentation": {}
    },
    {
        "label": "CONTRAST_WORDS",
        "kind": 5,
        "importPath": "sentiment_analysis.indonesian_sentiment_lexicon",
        "description": "sentiment_analysis.indonesian_sentiment_lexicon",
        "peekOfCode": "CONTRAST_WORDS = {\"tetapi\", \"namun\", \"tapi\", \"padahal\", \"cuma\", \"sayangnya\"}\nNEGATION_WORDS = {\"tidak\", \"bukan\", \"jangan\", \"tak\"}",
        "detail": "sentiment_analysis.indonesian_sentiment_lexicon",
        "documentation": {}
    },
    {
        "label": "NEGATION_WORDS",
        "kind": 5,
        "importPath": "sentiment_analysis.indonesian_sentiment_lexicon",
        "description": "sentiment_analysis.indonesian_sentiment_lexicon",
        "peekOfCode": "NEGATION_WORDS = {\"tidak\", \"bukan\", \"jangan\", \"tak\"}",
        "detail": "sentiment_analysis.indonesian_sentiment_lexicon",
        "documentation": {}
    },
    {
        "label": "load_words_from_txt",
        "kind": 2,
        "importPath": "sentiment_analysis.sentiment_analysis",
        "description": "sentiment_analysis.sentiment_analysis",
        "peekOfCode": "def load_words_from_txt(path):\n    with open(path, 'r', encoding='utf-8') as file:\n        return set(line.strip().lower() for line in file if line.strip())\nPOSITIVE_WORDS = load_words_from_txt('sentiment_analysis/positive.txt')\nNEGATIVE_WORDS = load_words_from_txt('sentiment_analysis/negative.txt')\ndef analyze_sentiment(text):\n    text = text.lower()\n    words = re.findall(r'\\b\\w+\\b', text)\n    pos_count = sum(1 for word in words if word in POSITIVE_WORDS)\n    neg_count = sum(1 for word in words if word in NEGATIVE_WORDS)",
        "detail": "sentiment_analysis.sentiment_analysis",
        "documentation": {}
    },
    {
        "label": "analyze_sentiment",
        "kind": 2,
        "importPath": "sentiment_analysis.sentiment_analysis",
        "description": "sentiment_analysis.sentiment_analysis",
        "peekOfCode": "def analyze_sentiment(text):\n    text = text.lower()\n    words = re.findall(r'\\b\\w+\\b', text)\n    pos_count = sum(1 for word in words if word in POSITIVE_WORDS)\n    neg_count = sum(1 for word in words if word in NEGATIVE_WORDS)\n    if pos_count > neg_count:\n        sentiment = \"positive\"\n    elif neg_count > pos_count:\n        sentiment = \"negative\"\n    else:",
        "detail": "sentiment_analysis.sentiment_analysis",
        "documentation": {}
    },
    {
        "label": "POSITIVE_WORDS",
        "kind": 5,
        "importPath": "sentiment_analysis.sentiment_analysis",
        "description": "sentiment_analysis.sentiment_analysis",
        "peekOfCode": "POSITIVE_WORDS = load_words_from_txt('sentiment_analysis/positive.txt')\nNEGATIVE_WORDS = load_words_from_txt('sentiment_analysis/negative.txt')\ndef analyze_sentiment(text):\n    text = text.lower()\n    words = re.findall(r'\\b\\w+\\b', text)\n    pos_count = sum(1 for word in words if word in POSITIVE_WORDS)\n    neg_count = sum(1 for word in words if word in NEGATIVE_WORDS)\n    if pos_count > neg_count:\n        sentiment = \"positive\"\n    elif neg_count > pos_count:",
        "detail": "sentiment_analysis.sentiment_analysis",
        "documentation": {}
    },
    {
        "label": "NEGATIVE_WORDS",
        "kind": 5,
        "importPath": "sentiment_analysis.sentiment_analysis",
        "description": "sentiment_analysis.sentiment_analysis",
        "peekOfCode": "NEGATIVE_WORDS = load_words_from_txt('sentiment_analysis/negative.txt')\ndef analyze_sentiment(text):\n    text = text.lower()\n    words = re.findall(r'\\b\\w+\\b', text)\n    pos_count = sum(1 for word in words if word in POSITIVE_WORDS)\n    neg_count = sum(1 for word in words if word in NEGATIVE_WORDS)\n    if pos_count > neg_count:\n        sentiment = \"positive\"\n    elif neg_count > pos_count:\n        sentiment = \"negative\"",
        "detail": "sentiment_analysis.sentiment_analysis",
        "documentation": {}
    },
    {
        "label": "load_words_from_txt",
        "kind": 2,
        "importPath": "sentiment_analysis.tfidf_lexicon_sentiment_analysis",
        "description": "sentiment_analysis.tfidf_lexicon_sentiment_analysis",
        "peekOfCode": "def load_words_from_txt(path):\n    with open(path, 'r', encoding='utf-8') as file:\n        return set(line.strip().lower() for line in file if line.strip())\nPOSITIVE_WORDS = load_words_from_txt('sentiment_analysis/positive.txt')\nNEGATIVE_WORDS = load_words_from_txt('sentiment_analysis/negative.txt')\nMODEL = joblib.load('sentiment_analysis/sentiment_model.pkl')\ndef extract_features(text):\n    text = text.lower()\n    words = re.findall(r'\\b\\w+\\b', text)\n    pos_count = sum(1 for word in words if word in POSITIVE_WORDS)",
        "detail": "sentiment_analysis.tfidf_lexicon_sentiment_analysis",
        "documentation": {}
    },
    {
        "label": "extract_features",
        "kind": 2,
        "importPath": "sentiment_analysis.tfidf_lexicon_sentiment_analysis",
        "description": "sentiment_analysis.tfidf_lexicon_sentiment_analysis",
        "peekOfCode": "def extract_features(text):\n    text = text.lower()\n    words = re.findall(r'\\b\\w+\\b', text)\n    pos_count = sum(1 for word in words if word in POSITIVE_WORDS)\n    neg_count = sum(1 for word in words if word in NEGATIVE_WORDS)\n    has_negation = any(word in NEGATION_WORDS for word in words)\n    has_contrast = any(word in CONTRAST_WORDS for word in words)\n    word_count = len(words)\n    return {\n        \"pos_count\": pos_count,",
        "detail": "sentiment_analysis.tfidf_lexicon_sentiment_analysis",
        "documentation": {}
    },
    {
        "label": "analyze_sentiment",
        "kind": 2,
        "importPath": "sentiment_analysis.tfidf_lexicon_sentiment_analysis",
        "description": "sentiment_analysis.tfidf_lexicon_sentiment_analysis",
        "peekOfCode": "def analyze_sentiment(text):\n    features = extract_features(text)\n    df = pd.DataFrame([features])\n    sentiment = MODEL.predict(df)[0]\n    return sentiment, features[\"pos_count\"], features[\"neg_count\"]",
        "detail": "sentiment_analysis.tfidf_lexicon_sentiment_analysis",
        "documentation": {}
    },
    {
        "label": "POSITIVE_WORDS",
        "kind": 5,
        "importPath": "sentiment_analysis.tfidf_lexicon_sentiment_analysis",
        "description": "sentiment_analysis.tfidf_lexicon_sentiment_analysis",
        "peekOfCode": "POSITIVE_WORDS = load_words_from_txt('sentiment_analysis/positive.txt')\nNEGATIVE_WORDS = load_words_from_txt('sentiment_analysis/negative.txt')\nMODEL = joblib.load('sentiment_analysis/sentiment_model.pkl')\ndef extract_features(text):\n    text = text.lower()\n    words = re.findall(r'\\b\\w+\\b', text)\n    pos_count = sum(1 for word in words if word in POSITIVE_WORDS)\n    neg_count = sum(1 for word in words if word in NEGATIVE_WORDS)\n    has_negation = any(word in NEGATION_WORDS for word in words)\n    has_contrast = any(word in CONTRAST_WORDS for word in words)",
        "detail": "sentiment_analysis.tfidf_lexicon_sentiment_analysis",
        "documentation": {}
    },
    {
        "label": "NEGATIVE_WORDS",
        "kind": 5,
        "importPath": "sentiment_analysis.tfidf_lexicon_sentiment_analysis",
        "description": "sentiment_analysis.tfidf_lexicon_sentiment_analysis",
        "peekOfCode": "NEGATIVE_WORDS = load_words_from_txt('sentiment_analysis/negative.txt')\nMODEL = joblib.load('sentiment_analysis/sentiment_model.pkl')\ndef extract_features(text):\n    text = text.lower()\n    words = re.findall(r'\\b\\w+\\b', text)\n    pos_count = sum(1 for word in words if word in POSITIVE_WORDS)\n    neg_count = sum(1 for word in words if word in NEGATIVE_WORDS)\n    has_negation = any(word in NEGATION_WORDS for word in words)\n    has_contrast = any(word in CONTRAST_WORDS for word in words)\n    word_count = len(words)",
        "detail": "sentiment_analysis.tfidf_lexicon_sentiment_analysis",
        "documentation": {}
    },
    {
        "label": "MODEL",
        "kind": 5,
        "importPath": "sentiment_analysis.tfidf_lexicon_sentiment_analysis",
        "description": "sentiment_analysis.tfidf_lexicon_sentiment_analysis",
        "peekOfCode": "MODEL = joblib.load('sentiment_analysis/sentiment_model.pkl')\ndef extract_features(text):\n    text = text.lower()\n    words = re.findall(r'\\b\\w+\\b', text)\n    pos_count = sum(1 for word in words if word in POSITIVE_WORDS)\n    neg_count = sum(1 for word in words if word in NEGATIVE_WORDS)\n    has_negation = any(word in NEGATION_WORDS for word in words)\n    has_contrast = any(word in CONTRAST_WORDS for word in words)\n    word_count = len(words)\n    return {",
        "detail": "sentiment_analysis.tfidf_lexicon_sentiment_analysis",
        "documentation": {}
    },
    {
        "label": "load_words_from_txt",
        "kind": 2,
        "importPath": "sentiment_analysis.train_sentiment_model",
        "description": "sentiment_analysis.train_sentiment_model",
        "peekOfCode": "def load_words_from_txt(path):\n    with open(path, 'r', encoding='utf-8') as file:\n        return set(line.strip().lower() for line in file if line.strip())\nPOSITIVE_WORDS = load_words_from_txt('sentiment_analysis/positive.txt')\nNEGATIVE_WORDS = load_words_from_txt('sentiment_analysis/negative.txt')\nNEGATION_WORDS = {\"tidak\", \"bukan\", \"jangan\", \"tanpa\"}\nCONTRAST_WORDS = {\"tetapi\", \"namun\", \"meskipun\", \"walaupun\"}\n# Extract lexical features\ndef extract_features(text):\n    text = text.lower()",
        "detail": "sentiment_analysis.train_sentiment_model",
        "documentation": {}
    },
    {
        "label": "extract_features",
        "kind": 2,
        "importPath": "sentiment_analysis.train_sentiment_model",
        "description": "sentiment_analysis.train_sentiment_model",
        "peekOfCode": "def extract_features(text):\n    text = text.lower()\n    words = re.findall(r'\\b\\w+\\b', text)\n    return {\n        \"pos_count\": sum(word in POSITIVE_WORDS for word in words),\n        \"neg_count\": sum(word in NEGATIVE_WORDS for word in words),\n        \"has_negation\": int(any(word in NEGATION_WORDS for word in words)),\n        \"has_contrast\": int(any(word in CONTRAST_WORDS for word in words)),\n        \"word_count\": len(words)\n    }",
        "detail": "sentiment_analysis.train_sentiment_model",
        "documentation": {}
    },
    {
        "label": "POSITIVE_WORDS",
        "kind": 5,
        "importPath": "sentiment_analysis.train_sentiment_model",
        "description": "sentiment_analysis.train_sentiment_model",
        "peekOfCode": "POSITIVE_WORDS = load_words_from_txt('sentiment_analysis/positive.txt')\nNEGATIVE_WORDS = load_words_from_txt('sentiment_analysis/negative.txt')\nNEGATION_WORDS = {\"tidak\", \"bukan\", \"jangan\", \"tanpa\"}\nCONTRAST_WORDS = {\"tetapi\", \"namun\", \"meskipun\", \"walaupun\"}\n# Extract lexical features\ndef extract_features(text):\n    text = text.lower()\n    words = re.findall(r'\\b\\w+\\b', text)\n    return {\n        \"pos_count\": sum(word in POSITIVE_WORDS for word in words),",
        "detail": "sentiment_analysis.train_sentiment_model",
        "documentation": {}
    },
    {
        "label": "NEGATIVE_WORDS",
        "kind": 5,
        "importPath": "sentiment_analysis.train_sentiment_model",
        "description": "sentiment_analysis.train_sentiment_model",
        "peekOfCode": "NEGATIVE_WORDS = load_words_from_txt('sentiment_analysis/negative.txt')\nNEGATION_WORDS = {\"tidak\", \"bukan\", \"jangan\", \"tanpa\"}\nCONTRAST_WORDS = {\"tetapi\", \"namun\", \"meskipun\", \"walaupun\"}\n# Extract lexical features\ndef extract_features(text):\n    text = text.lower()\n    words = re.findall(r'\\b\\w+\\b', text)\n    return {\n        \"pos_count\": sum(word in POSITIVE_WORDS for word in words),\n        \"neg_count\": sum(word in NEGATIVE_WORDS for word in words),",
        "detail": "sentiment_analysis.train_sentiment_model",
        "documentation": {}
    },
    {
        "label": "NEGATION_WORDS",
        "kind": 5,
        "importPath": "sentiment_analysis.train_sentiment_model",
        "description": "sentiment_analysis.train_sentiment_model",
        "peekOfCode": "NEGATION_WORDS = {\"tidak\", \"bukan\", \"jangan\", \"tanpa\"}\nCONTRAST_WORDS = {\"tetapi\", \"namun\", \"meskipun\", \"walaupun\"}\n# Extract lexical features\ndef extract_features(text):\n    text = text.lower()\n    words = re.findall(r'\\b\\w+\\b', text)\n    return {\n        \"pos_count\": sum(word in POSITIVE_WORDS for word in words),\n        \"neg_count\": sum(word in NEGATIVE_WORDS for word in words),\n        \"has_negation\": int(any(word in NEGATION_WORDS for word in words)),",
        "detail": "sentiment_analysis.train_sentiment_model",
        "documentation": {}
    },
    {
        "label": "CONTRAST_WORDS",
        "kind": 5,
        "importPath": "sentiment_analysis.train_sentiment_model",
        "description": "sentiment_analysis.train_sentiment_model",
        "peekOfCode": "CONTRAST_WORDS = {\"tetapi\", \"namun\", \"meskipun\", \"walaupun\"}\n# Extract lexical features\ndef extract_features(text):\n    text = text.lower()\n    words = re.findall(r'\\b\\w+\\b', text)\n    return {\n        \"pos_count\": sum(word in POSITIVE_WORDS for word in words),\n        \"neg_count\": sum(word in NEGATIVE_WORDS for word in words),\n        \"has_negation\": int(any(word in NEGATION_WORDS for word in words)),\n        \"has_contrast\": int(any(word in CONTRAST_WORDS for word in words)),",
        "detail": "sentiment_analysis.train_sentiment_model",
        "documentation": {}
    },
    {
        "label": "df",
        "kind": 5,
        "importPath": "sentiment_analysis.train_sentiment_model",
        "description": "sentiment_analysis.train_sentiment_model",
        "peekOfCode": "df = pd.read_csv(\"sentiment_analysis/labeled_reviews.csv\")\ndf.dropna(subset=[\"review\", \"label\"], inplace=True)\n# Extract features\nlexical_features = df[\"review\"].apply(extract_features).apply(pd.Series)\n# TF-IDF Vectorization\ntfidf = TfidfVectorizer(ngram_range=(1, 2), max_features=3000)\ntfidf_features = tfidf.fit_transform(df[\"review\"])\n# Combine TF-IDF + Lexical features\nfrom numpy import array\nX_combined = hstack([tfidf_features, array(lexical_features)])",
        "detail": "sentiment_analysis.train_sentiment_model",
        "documentation": {}
    },
    {
        "label": "lexical_features",
        "kind": 5,
        "importPath": "sentiment_analysis.train_sentiment_model",
        "description": "sentiment_analysis.train_sentiment_model",
        "peekOfCode": "lexical_features = df[\"review\"].apply(extract_features).apply(pd.Series)\n# TF-IDF Vectorization\ntfidf = TfidfVectorizer(ngram_range=(1, 2), max_features=3000)\ntfidf_features = tfidf.fit_transform(df[\"review\"])\n# Combine TF-IDF + Lexical features\nfrom numpy import array\nX_combined = hstack([tfidf_features, array(lexical_features)])\ny = df[\"label\"]\n# Optional: Handle imbalanced dataset\nsmote = SMOTE(random_state=42)",
        "detail": "sentiment_analysis.train_sentiment_model",
        "documentation": {}
    },
    {
        "label": "tfidf",
        "kind": 5,
        "importPath": "sentiment_analysis.train_sentiment_model",
        "description": "sentiment_analysis.train_sentiment_model",
        "peekOfCode": "tfidf = TfidfVectorizer(ngram_range=(1, 2), max_features=3000)\ntfidf_features = tfidf.fit_transform(df[\"review\"])\n# Combine TF-IDF + Lexical features\nfrom numpy import array\nX_combined = hstack([tfidf_features, array(lexical_features)])\ny = df[\"label\"]\n# Optional: Handle imbalanced dataset\nsmote = SMOTE(random_state=42)\nX_combined, y = smote.fit_resample(X_combined, y)\n# Train/test split",
        "detail": "sentiment_analysis.train_sentiment_model",
        "documentation": {}
    },
    {
        "label": "tfidf_features",
        "kind": 5,
        "importPath": "sentiment_analysis.train_sentiment_model",
        "description": "sentiment_analysis.train_sentiment_model",
        "peekOfCode": "tfidf_features = tfidf.fit_transform(df[\"review\"])\n# Combine TF-IDF + Lexical features\nfrom numpy import array\nX_combined = hstack([tfidf_features, array(lexical_features)])\ny = df[\"label\"]\n# Optional: Handle imbalanced dataset\nsmote = SMOTE(random_state=42)\nX_combined, y = smote.fit_resample(X_combined, y)\n# Train/test split\nX_train, X_test, y_train, y_test = train_test_split(X_combined, y, test_size=0.2, stratify=y, random_state=42)",
        "detail": "sentiment_analysis.train_sentiment_model",
        "documentation": {}
    },
    {
        "label": "X_combined",
        "kind": 5,
        "importPath": "sentiment_analysis.train_sentiment_model",
        "description": "sentiment_analysis.train_sentiment_model",
        "peekOfCode": "X_combined = hstack([tfidf_features, array(lexical_features)])\ny = df[\"label\"]\n# Optional: Handle imbalanced dataset\nsmote = SMOTE(random_state=42)\nX_combined, y = smote.fit_resample(X_combined, y)\n# Train/test split\nX_train, X_test, y_train, y_test = train_test_split(X_combined, y, test_size=0.2, stratify=y, random_state=42)\n# Train model\nclf = LogisticRegression(max_iter=1000, class_weight=\"balanced\", random_state=42)\nclf.fit(X_train, y_train)",
        "detail": "sentiment_analysis.train_sentiment_model",
        "documentation": {}
    },
    {
        "label": "y",
        "kind": 5,
        "importPath": "sentiment_analysis.train_sentiment_model",
        "description": "sentiment_analysis.train_sentiment_model",
        "peekOfCode": "y = df[\"label\"]\n# Optional: Handle imbalanced dataset\nsmote = SMOTE(random_state=42)\nX_combined, y = smote.fit_resample(X_combined, y)\n# Train/test split\nX_train, X_test, y_train, y_test = train_test_split(X_combined, y, test_size=0.2, stratify=y, random_state=42)\n# Train model\nclf = LogisticRegression(max_iter=1000, class_weight=\"balanced\", random_state=42)\nclf.fit(X_train, y_train)\n# Evaluate",
        "detail": "sentiment_analysis.train_sentiment_model",
        "documentation": {}
    },
    {
        "label": "smote",
        "kind": 5,
        "importPath": "sentiment_analysis.train_sentiment_model",
        "description": "sentiment_analysis.train_sentiment_model",
        "peekOfCode": "smote = SMOTE(random_state=42)\nX_combined, y = smote.fit_resample(X_combined, y)\n# Train/test split\nX_train, X_test, y_train, y_test = train_test_split(X_combined, y, test_size=0.2, stratify=y, random_state=42)\n# Train model\nclf = LogisticRegression(max_iter=1000, class_weight=\"balanced\", random_state=42)\nclf.fit(X_train, y_train)\n# Evaluate\ny_pred = clf.predict(X_test)\nprint(classification_report(y_test, y_pred))",
        "detail": "sentiment_analysis.train_sentiment_model",
        "documentation": {}
    },
    {
        "label": "clf",
        "kind": 5,
        "importPath": "sentiment_analysis.train_sentiment_model",
        "description": "sentiment_analysis.train_sentiment_model",
        "peekOfCode": "clf = LogisticRegression(max_iter=1000, class_weight=\"balanced\", random_state=42)\nclf.fit(X_train, y_train)\n# Evaluate\ny_pred = clf.predict(X_test)\nprint(classification_report(y_test, y_pred))\n# Save model and vectorizer\njoblib.dump(clf, \"sentiment_analysis/sentiment_model.pkl\")\njoblib.dump(tfidf, \"sentiment_analysis/tfidf_vectorizer.pkl\")",
        "detail": "sentiment_analysis.train_sentiment_model",
        "documentation": {}
    },
    {
        "label": "y_pred",
        "kind": 5,
        "importPath": "sentiment_analysis.train_sentiment_model",
        "description": "sentiment_analysis.train_sentiment_model",
        "peekOfCode": "y_pred = clf.predict(X_test)\nprint(classification_report(y_test, y_pred))\n# Save model and vectorizer\njoblib.dump(clf, \"sentiment_analysis/sentiment_model.pkl\")\njoblib.dump(tfidf, \"sentiment_analysis/tfidf_vectorizer.pkl\")",
        "detail": "sentiment_analysis.train_sentiment_model",
        "documentation": {}
    },
    {
        "label": "app",
        "kind": 5,
        "importPath": "app",
        "description": "app",
        "peekOfCode": "app = Flask(__name__)\nCORS(app)\napp.config[\"MONGO_URI\"] = MONGO_URI\nrevenue_bp = create_revenue_blueprint(app)\napp.register_blueprint(revenue_bp)\nreviews_bp = create_review_blueprint(app)\napp.register_blueprint(reviews_bp)  \nsentiments_bp = create_sentiment_blueprint(app)\napp.register_blueprint(sentiments_bp)\nhotels_bp = create_hotel_blueprint(app)",
        "detail": "app",
        "documentation": {}
    },
    {
        "label": "app.config[\"MONGO_URI\"]",
        "kind": 5,
        "importPath": "app",
        "description": "app",
        "peekOfCode": "app.config[\"MONGO_URI\"] = MONGO_URI\nrevenue_bp = create_revenue_blueprint(app)\napp.register_blueprint(revenue_bp)\nreviews_bp = create_review_blueprint(app)\napp.register_blueprint(reviews_bp)  \nsentiments_bp = create_sentiment_blueprint(app)\napp.register_blueprint(sentiments_bp)\nhotels_bp = create_hotel_blueprint(app)\napp.register_blueprint(hotels_bp)\nif __name__ == \"__main__\":",
        "detail": "app",
        "documentation": {}
    },
    {
        "label": "revenue_bp",
        "kind": 5,
        "importPath": "app",
        "description": "app",
        "peekOfCode": "revenue_bp = create_revenue_blueprint(app)\napp.register_blueprint(revenue_bp)\nreviews_bp = create_review_blueprint(app)\napp.register_blueprint(reviews_bp)  \nsentiments_bp = create_sentiment_blueprint(app)\napp.register_blueprint(sentiments_bp)\nhotels_bp = create_hotel_blueprint(app)\napp.register_blueprint(hotels_bp)\nif __name__ == \"__main__\":\n    app.run(debug=False)",
        "detail": "app",
        "documentation": {}
    },
    {
        "label": "reviews_bp",
        "kind": 5,
        "importPath": "app",
        "description": "app",
        "peekOfCode": "reviews_bp = create_review_blueprint(app)\napp.register_blueprint(reviews_bp)  \nsentiments_bp = create_sentiment_blueprint(app)\napp.register_blueprint(sentiments_bp)\nhotels_bp = create_hotel_blueprint(app)\napp.register_blueprint(hotels_bp)\nif __name__ == \"__main__\":\n    app.run(debug=False)",
        "detail": "app",
        "documentation": {}
    },
    {
        "label": "sentiments_bp",
        "kind": 5,
        "importPath": "app",
        "description": "app",
        "peekOfCode": "sentiments_bp = create_sentiment_blueprint(app)\napp.register_blueprint(sentiments_bp)\nhotels_bp = create_hotel_blueprint(app)\napp.register_blueprint(hotels_bp)\nif __name__ == \"__main__\":\n    app.run(debug=False)",
        "detail": "app",
        "documentation": {}
    },
    {
        "label": "hotels_bp",
        "kind": 5,
        "importPath": "app",
        "description": "app",
        "peekOfCode": "hotels_bp = create_hotel_blueprint(app)\napp.register_blueprint(hotels_bp)\nif __name__ == \"__main__\":\n    app.run(debug=False)",
        "detail": "app",
        "documentation": {}
    },
    {
        "label": "MONGO_URI",
        "kind": 5,
        "importPath": "config",
        "description": "config",
        "peekOfCode": "MONGO_URI = \"mongodb+srv://williamongkywow:williamongkywow@clusterta.poz3g.mongodb.net/hotelPerformance\"",
        "detail": "config",
        "documentation": {}
    }
]